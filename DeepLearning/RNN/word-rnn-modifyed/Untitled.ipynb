{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "import argparse\n",
    "import time\n",
    "import os\n",
    "from six.moves import cPickle\n",
    "\n",
    "import collections\n",
    "from six.moves import cPickle\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import seq2seq\n",
    "\n",
    "import random\n",
    "\n",
    "from beam import BeamSearch\n",
    "from utils import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 3\n",
      "seq_length: 2\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--data_dir', type=str, default='data/tiny',\n",
    "                    help='data directory containing input.txt')\n",
    "parser.add_argument('--save_dir', type=str, default='save',\n",
    "                    help='directory to store checkpointed models')\n",
    "parser.add_argument('--rnn_size', type=int, default=4,\n",
    "                    help='size of RNN hidden state')\n",
    "parser.add_argument('--num_layers', type=int, default=1,\n",
    "                    help='number of layers in the RNN')\n",
    "parser.add_argument('--model', type=str, default='rnn',\n",
    "                    help='rnn, gru, or lstm')\n",
    "parser.add_argument('--batch_size', type=int, default=3,\n",
    "                    help='minibatch size')\n",
    "parser.add_argument('--seq_length', type=int, default=2,\n",
    "                    help='RNN sequence length')\n",
    "parser.add_argument('--num_epochs', type=int, default=50,\n",
    "                    help='number of epochs')\n",
    "parser.add_argument('--save_every', type=int, default=100,\n",
    "                    help='save frequency')\n",
    "parser.add_argument('--grad_clip', type=float, default=5.,\n",
    "                    help='clip gradients at this value')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.002,\n",
    "                    help='learning rate')\n",
    "parser.add_argument('--decay_rate', type=float, default=0.97,\n",
    "                    help='decay rate for rmsprop')\n",
    "parser.add_argument('--init_from', type=str, default=None,\n",
    "                    help=\"\"\"continue training from saved model at this path. Path must contain files saved by previous training process:\n",
    "                        'config.pkl'        : configuration;\n",
    "                        'vocab.pkl'   : vocabulary definitions;\n",
    "                        'checkpoint'        : paths to model file(s) (created by tf).\n",
    "                                              Note: this file contains absolute paths, be careful when moving files around;\n",
    "                        'model.ckpt-*'      : file(s) with model definition (created by tf)\n",
    "                    \"\"\")\n",
    "parser.add_argument('-f', type=str, default=None)\n",
    "args = parser.parse_args()\n",
    "\n",
    "print(\"batch_size:\", args.batch_size)\n",
    "print(\"seq_length:\", args.seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading text file\n",
      "data_loader.vocab\n",
      "죽느냐 : 6\n",
      "그것이 : 0\n",
      "윌리엄 : 5\n",
      "말했습니다.: 1\n",
      "세익스피어는: 4\n",
      "문제라고: 2\n",
      "사느냐 : 3\n",
      "data_loader.words\n",
      "그것이 \n",
      "말했습니다.\n",
      "문제라고\n",
      "사느냐 \n",
      "세익스피어는\n",
      "윌리엄 \n",
      "죽느냐 \n",
      "data_loader.vocab_size: 7\n",
      "\n",
      "data_loader.tensor [5 4 6 3 0 2 1 5 4 6 3 0 2 1 5 4 6 3]\n",
      "\n",
      "data_loader.num_batches 3\n",
      "\n",
      "data_loader.x_batches [array([[5, 4],\n",
      "       [1, 5],\n",
      "       [2, 1]]), array([[6, 3],\n",
      "       [4, 6],\n",
      "       [5, 4]]), array([[0, 2],\n",
      "       [3, 0],\n",
      "       [6, 3]])]\n",
      "data_loader.y_batches [array([[4, 6],\n",
      "       [5, 4],\n",
      "       [1, 5]]), array([[3, 0],\n",
      "       [6, 3],\n",
      "       [4, 6]]), array([[2, 1],\n",
      "       [0, 2],\n",
      "       [3, 5]])]\n"
     ]
    }
   ],
   "source": [
    "data_loader = TextLoader(args.data_dir, args.batch_size, args.seq_length)\n",
    "args.vocab_size = data_loader.vocab_size\n",
    "\n",
    "print(\"data_loader.vocab\")\n",
    "for item in data_loader.vocab.items():\n",
    "    print(\"{0:10s}:{1:2d}\".format(item[0], item[1]))\n",
    "\n",
    "print(\"data_loader.words\")\n",
    "for item in data_loader.words:\n",
    "    print(\"{0:10s}\".format(item))\n",
    "\n",
    "print(\"data_loader.vocab_size:\", data_loader.vocab_size)\n",
    "print()\n",
    "\n",
    "print(\"data_loader.tensor\", data_loader.tensor)\n",
    "print()\n",
    "\n",
    "print(\"data_loader.num_batches\", data_loader.num_batches)   # tensor.size / (batch_size * seq_length) = 6 / (2 * 3)\n",
    "print()\n",
    "\n",
    "print(\"data_loader.x_batches\", data_loader.x_batches)\n",
    "print(\"data_loader.y_batches\", data_loader.y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell = rnn_cell.BasicRNNCell(args.rnn_size)              # rnn_size=4\n",
    "cell = rnn_cell.MultiRNNCell([cell] * args.num_layers)   # num_layers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])  #(3, 2)\n",
    "targets = tf.placeholder(tf.int32, [args.batch_size, args.seq_length])     #(3, 2)\n",
    "initial_state = cell.zero_state(args.batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor 'zeros:0' shape=(3, 4) dtype=float32>,)\n"
     ]
    }
   ],
   "source": [
    "print(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(initial_state[0].eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_pointer = tf.Variable(0, name=\"batch_pointer\", trainable=False, dtype=tf.int32)\n",
    "inc_batch_pointer_op = tf.assign(batch_pointer, batch_pointer + 1)\n",
    "epoch_pointer = tf.Variable(0, name=\"epoch_pointer\", trainable=False, dtype=tf.int32)\n",
    "batch_time = tf.Variable(0.0, name=\"batch_time\", trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Assign_1:0' shape=() dtype=int32_ref>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_pointer.assign(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(batch_pointer.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('rnnlm', reuse=None):\n",
    "    softmax_w = tf.get_variable(\"softmax_w\", [args.rnn_size, args.vocab_size])    #(4, 7)\n",
    "    softmax_b = tf.get_variable(\"softmax_b\", [args.vocab_size])  #7\n",
    "    embedding = tf.get_variable(\"embedding\", [args.vocab_size, args.rnn_size])    #(7, 4)\n",
    "    embedding_lookup = tf.nn.embedding_lookup(embedding, input_data)\n",
    "    inputs_temp = tf.split(1, args.seq_length, embedding_lookup)\n",
    "    inputs = [tf.squeeze(input_, [1]) for input_ in inputs_temp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnnlm/softmax_w/read:0\", shape=(4, 7), dtype=float32)\n",
      "Tensor(\"rnnlm/softmax_b/read:0\", shape=(7,), dtype=float32)\n",
      "Tensor(\"rnnlm/embedding/read:0\", shape=(7, 4), dtype=float32)\n",
      "Tensor(\"rnnlm/embedding_lookup:0\", shape=(3, 2, 4), dtype=float32)\n",
      "[<tf.Tensor 'rnnlm/split:0' shape=(3, 1, 4) dtype=float32>, <tf.Tensor 'rnnlm/split:1' shape=(3, 1, 4) dtype=float32>]\n",
      "[<tf.Tensor 'rnnlm/Squeeze:0' shape=(3, 4) dtype=float32>, <tf.Tensor 'rnnlm/Squeeze_1:0' shape=(3, 4) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(softmax_w)\n",
    "print(softmax_b)\n",
    "print(embedding)\n",
    "print(embedding_lookup)\n",
    "print(inputs_temp)\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope('rnnlm', reuse=None):\n",
    "    outputs, last_state = seq2seq.rnn_decoder(inputs, initial_state, cell, scope='rnnlm')\n",
    "    output = tf.reshape(tf.concat(1, outputs), [-1, args.rnn_size])\n",
    "\n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    probs = tf.nn.softmax(logits)\n",
    "\n",
    "    loss = seq2seq.sequence_loss_by_example([logits],\n",
    "                                            [tf.reshape(targets, [-1])],\n",
    "                                            [tf.ones([args.batch_size * args.seq_length])],\n",
    "                                            args.vocab_size)\n",
    "    \n",
    "    cost = tf.reduce_sum(loss) / args.batch_size / args.seq_length\n",
    "    final_state = last_state\n",
    "    \n",
    "    lr = tf.Variable(0.0, trainable=False)\n",
    "    tvars = tf.trainable_variables()\n",
    "    grads, _ = tf.clip_by_global_norm(tf.gradients(cost, tvars), args.grad_clip)\n",
    "    optimizer = tf.train.AdamOptimizer(lr)\n",
    "    train_op = optimizer.apply_gradients(zip(grads, tvars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x, y = data_loader.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "state = session.run(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feed = {input_data: x, targets: y, initial_state: state}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loss, state, _, _ = session.run([cost, final_state, train_op, inc_batch_pointer_op], feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnnlm_1/Reshape:0\", shape=(6, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 3]\n",
      " [4 6]\n",
      " [5 4]]\n",
      "[[3 0]\n",
      " [6 3]\n",
      " [4 6]]\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnnlm/softmax_w/read:0\", shape=(4, 7), dtype=float32)\n",
      "[[-0.63689959 -0.47216704  0.297059    0.16834491 -0.54989243 -0.32636529\n",
      "   0.17637902]\n",
      " [-0.78735244  0.54169887  0.53561395  0.48295254  0.10195148 -0.75769854\n",
      "   0.37552732]\n",
      " [ 0.15824944  0.39673597 -0.66539979  0.50263208 -0.83951503 -0.26330036\n",
      "   0.81498832]\n",
      " [ 0.22424036 -0.20029074 -0.25088799  0.77444297 -0.15448761  0.014449\n",
      "  -0.59497726]]\n",
      "\n",
      "Tensor(\"rnnlm/softmax_b/read:0\", shape=(7,), dtype=float32)\n",
      "[ 1.08843982 -0.6445905   0.13676846 -0.36762774 -1.26939881  0.41135585\n",
      "  0.97577727]\n",
      "\n",
      "Tensor(\"rnnlm/embedding/read:0\", shape=(7, 4), dtype=float32)\n",
      "[[ 0.09611398 -0.21043825  0.4852308  -0.34034497]\n",
      " [-0.08064193  0.60480046 -0.57025039  0.02360171]\n",
      " [-0.29699752 -0.48134381  0.35710895  0.35222185]\n",
      " [-0.6222471  -0.35754392  0.5245924  -0.05367881]\n",
      " [-0.49833781  0.47993124  0.14076376  0.58626771]\n",
      " [ 0.13575166 -0.18456259  0.39192641  0.23433405]\n",
      " [ 0.09423882  0.40222573 -0.46399361  0.13300931]]\n",
      "\n",
      "Tensor(\"rnnlm/rnnlm/MultiRNNCell/Cell0/BasicRNNCell/Linear/Matrix/read:0\", shape=(8, 4), dtype=float32)\n",
      "[[ 0.59058756  0.54950076  0.44813329  0.01832592]\n",
      " [-0.44707075  0.1309306  -0.03932416  0.37513345]\n",
      " [ 0.58211011  0.11162549  0.13845503  0.0650785 ]\n",
      " [ 0.28776878 -0.16163957  0.56545144 -0.53555566]\n",
      " [ 0.58512658 -0.16291416  0.25162625 -0.21148911]\n",
      " [-0.03481436  0.01535505  0.34932745 -0.54433823]\n",
      " [ 0.0560993   0.37305874  0.2873258   0.00439918]\n",
      " [-0.21125421 -0.56833696 -0.35355142 -0.1516715 ]]\n",
      "\n",
      "Tensor(\"rnnlm/rnnlm/MultiRNNCell/Cell0/BasicRNNCell/Linear/Bias/read:0\", shape=(4,), dtype=float32)\n",
      "[ 0.  0.  0.  0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tvar in tvars:\n",
    "    print(tvar)\n",
    "    print(tvar.eval())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
