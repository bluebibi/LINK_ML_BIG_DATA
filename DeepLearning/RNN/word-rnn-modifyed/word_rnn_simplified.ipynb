{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-*- coding: utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import collections\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "\n",
    "from tensorflow.python.ops import rnn_cell\n",
    "from tensorflow.python.ops import seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size    = 3 #minibatch size\n",
    "seq_length    = 6 #RNN sequence length\n",
    "learning_rate = 0.002\n",
    "decay_rate    = 0.97\n",
    "num_epochs    = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_text = u\"\"\"윌리엄 세익스피어는 죽느냐 사느냐 그것이 문제라고 말했습니다.\n",
    "                윌리엄 세익스피어는 죽느냐 사느냐 그것이 문제라고 말했습니다. \n",
    "                윌리엄 세익스피어는 죽느냐 사느냐 그것이 문제라고 말했습니다.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_text = input_text.split()\n",
    "\n",
    "word_counts = collections.Counter(x_text)\n",
    "# Mapping from index to word\n",
    "words = [x[0] for x in word_counts.most_common()]\n",
    "words = list(sorted(words))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(words)}\n",
    "vocab_size = len(words)\n",
    "\n",
    "words_index_list = np.array(list(map(vocab.get, x_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['그것이', '말했습니다.', '문제라고', '사느냐', '세익스피어는', '윌리엄', '죽느냐']\n"
     ]
    }
   ],
   "source": [
    "print repr([word.encode(sys.stdout.encoding) for word in words]).decode('string-escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('세익스피어는', 4), ('문제라고', 2), ('죽느냐', 6), ('사느냐', 3), ('말했습니다.', 1), ('그것이', 0), ('윌리엄', 5)]\n"
     ]
    }
   ],
   "source": [
    "print repr([(item[0].encode(sys.stdout.encoding), item[1]) for item in vocab.items()]).decode('string-escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "print vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 6 3 0 2 1 5 4 6 3 0 2 1 5 4 6 3 0 2 1]\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print words_index_list\n",
    "print len(words_index_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(words_index_list.size / (batch_size * seq_length))\n",
    "print num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "tensor_size = num_batches * batch_size * seq_length\n",
    "print tensor_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensor = tensor[:tensor_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 6 3 0 2 1 5 4 6 3 0 2 1 5 4 6 3]\n"
     ]
    }
   ],
   "source": [
    "print tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([5, 4, 6, 3, 0, 2, 1, 5, 4, 6, 3, 0, 2, 1, 5, 4, 6, 3]), 18)\n",
      "(array([4, 6, 3, 0, 2, 1, 5, 4, 6, 3, 0, 2, 1, 5, 4, 6, 3, 5]), 18)\n"
     ]
    }
   ],
   "source": [
    "xdata = tensor\n",
    "ydata = np.copy(tensor)\n",
    "\n",
    "ydata[:-1] = xdata[1:]\n",
    "ydata[-1] = xdata[0]\n",
    "\n",
    "print(xdata, len(xdata))\n",
    "print(ydata, len(ydata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 4 6 3 0 2]\n",
      " [1 5 4 6 3 0]\n",
      " [2 1 5 4 6 3]]\n",
      "[[4 6 3 0 2 1]\n",
      " [5 4 6 3 0 2]\n",
      " [1 5 4 6 3 5]]\n"
     ]
    }
   ],
   "source": [
    "print(xdata.reshape(batch_size, -1))\n",
    "print(ydata.reshape(batch_size, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[5, 4, 6, 3, 0, 2],\n",
      "       [1, 5, 4, 6, 3, 0],\n",
      "       [2, 1, 5, 4, 6, 3]])]\n",
      "[array([[4, 6, 3, 0, 2, 1],\n",
      "       [5, 4, 6, 3, 0, 2],\n",
      "       [1, 5, 4, 6, 3, 5]])]\n"
     ]
    }
   ],
   "source": [
    "x_batches = np.split(xdata.reshape(batch_size, -1), num_batches, 1) #Split an array into multiple sub-arrays.\n",
    "y_batches = np.split(ydata.reshape(batch_size, -1), num_batches, 1)\n",
    "\n",
    "print(x_batches)\n",
    "print(y_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def next_batch(pointer):\n",
    "    x, y = x_batches[pointer], y_batches[pointer]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_units = vocab_size #size of RNN hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cell = rnn_cell.BasicRNNCell(num_units = num_units) # num_units = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "print initial_state.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input_data = tf.placeholder(tf.int32, [batch_size, seq_length])  #(3, 6)\n",
    "targets = tf.placeholder(tf.int32, [batch_size, seq_length])     #(3, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- word embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Variable_6/read:0\", shape=(7, 7), dtype=float32)\n",
      "\n",
      "Tensor(\"embedding_lookup_7:0\", shape=(3, 6, 7), dtype=float32)\n",
      "\n",
      "[<tf.Tensor 'split_6:0' shape=(3, 1, 7) dtype=float32>, <tf.Tensor 'split_6:1' shape=(3, 1, 7) dtype=float32>, <tf.Tensor 'split_6:2' shape=(3, 1, 7) dtype=float32>, <tf.Tensor 'split_6:3' shape=(3, 1, 7) dtype=float32>, <tf.Tensor 'split_6:4' shape=(3, 1, 7) dtype=float32>, <tf.Tensor 'split_6:5' shape=(3, 1, 7) dtype=float32>]\n",
      "\n",
      "[<tf.Tensor 'Squeeze_20:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'Squeeze_21:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'Squeeze_22:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'Squeeze_23:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'Squeeze_24:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'Squeeze_25:0' shape=(3, 7) dtype=float32>]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "embedding = tf.Variable(tf.random_uniform([vocab_size, num_units], -1.0, 1.0))    #(7, 7)\n",
    "print embedding;print\n",
    "\n",
    "embedding_lookup = tf.nn.embedding_lookup(embedding, input_data)\n",
    "print embedding_lookup;print\n",
    "\n",
    "inputs_temp = tf.split(1, seq_length, embedding_lookup)\n",
    "print inputs_temp;print\n",
    "\n",
    "inputs = [tf.squeeze(input_, [1]) for input_ in inputs_temp]\n",
    "print inputs;print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x, y = next_batch(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 4 6 3 0 2]\n",
      " [1 5 4 6 3 0]\n",
      " [2 1 5 4 6 3]]\n"
     ]
    }
   ],
   "source": [
    "print x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.41397262, -0.52421355, -0.26793003,  0.19232202,  0.48450661,\n",
       "          0.98198891, -0.33509398],\n",
       "        [-0.96061945,  0.07538652,  0.55114079, -0.8136189 , -0.66453218,\n",
       "          0.29499269,  0.73907971],\n",
       "        [-0.86935425, -0.04184699, -0.95249796, -0.292665  , -0.11538029,\n",
       "          0.96657205, -0.79084444]], dtype=float32),\n",
       " array([[ 0.6182487 ,  0.58449626,  0.71015429,  0.71422744,  0.27648664,\n",
       "         -0.83238077,  0.97287464],\n",
       "        [-0.41397262, -0.52421355, -0.26793003,  0.19232202,  0.48450661,\n",
       "          0.98198891, -0.33509398],\n",
       "        [-0.96061945,  0.07538652,  0.55114079, -0.8136189 , -0.66453218,\n",
       "          0.29499269,  0.73907971]], dtype=float32),\n",
       " array([[ 0.10757804,  0.44390416,  0.58406186,  0.54903483, -0.95282722,\n",
       "          0.39436197, -0.90446091],\n",
       "        [ 0.6182487 ,  0.58449626,  0.71015429,  0.71422744,  0.27648664,\n",
       "         -0.83238077,  0.97287464],\n",
       "        [-0.41397262, -0.52421355, -0.26793003,  0.19232202,  0.48450661,\n",
       "          0.98198891, -0.33509398]], dtype=float32),\n",
       " array([[-0.41128755,  0.8755455 , -0.54434299, -0.78897715, -0.59071326,\n",
       "         -0.78905058, -0.40689898],\n",
       "        [ 0.10757804,  0.44390416,  0.58406186,  0.54903483, -0.95282722,\n",
       "          0.39436197, -0.90446091],\n",
       "        [ 0.6182487 ,  0.58449626,  0.71015429,  0.71422744,  0.27648664,\n",
       "         -0.83238077,  0.97287464]], dtype=float32),\n",
       " array([[ 0.26018691, -0.11861515,  0.66512299,  0.09281898,  0.9393034 ,\n",
       "          0.99269748,  0.72414589],\n",
       "        [-0.41128755,  0.8755455 , -0.54434299, -0.78897715, -0.59071326,\n",
       "         -0.78905058, -0.40689898],\n",
       "        [ 0.10757804,  0.44390416,  0.58406186,  0.54903483, -0.95282722,\n",
       "          0.39436197, -0.90446091]], dtype=float32),\n",
       " array([[-0.86935425, -0.04184699, -0.95249796, -0.292665  , -0.11538029,\n",
       "          0.96657205, -0.79084444],\n",
       "        [ 0.26018691, -0.11861515,  0.66512299,  0.09281898,  0.9393034 ,\n",
       "          0.99269748,  0.72414589],\n",
       "        [-0.41128755,  0.8755455 , -0.54434299, -0.78897715, -0.59071326,\n",
       "         -0.78905058, -0.40689898]], dtype=float32)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.global_variables_initializer().run()\n",
    "session.run(inputs, {input_data: x})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnnlm_17/Variable/read:0\", shape=(7, 7), dtype=float32)\n",
      "Tensor(\"rnnlm_17/Variable_1/read:0\", shape=(7,), dtype=float32)\n",
      "[<tf.Tensor 'rnnlm_17/rnn_decoder/BasicRNNCell/Tanh:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'rnnlm_17/rnn_decoder/BasicRNNCell_1/Tanh:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'rnnlm_17/rnn_decoder/BasicRNNCell_2/Tanh:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'rnnlm_17/rnn_decoder/BasicRNNCell_3/Tanh:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'rnnlm_17/rnn_decoder/BasicRNNCell_4/Tanh:0' shape=(3, 7) dtype=float32>, <tf.Tensor 'rnnlm_17/rnn_decoder/BasicRNNCell_5/Tanh:0' shape=(3, 7) dtype=float32>]\n",
      "Tensor(\"rnnlm_17/Reshape:0\", shape=(18, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('rnnlm', reuse=True):\n",
    "    softmax_w = tf.Variable(tf.random_uniform([num_units, vocab_size]))    #(7, 7)\n",
    "    softmax_b = tf.Variable(tf.random_uniform([vocab_size]))  #7\n",
    "    \n",
    "    print softmax_w\n",
    "    print softmax_b\n",
    "\n",
    "    outputs, last_state = seq2seq.rnn_decoder(inputs, initial_state, cell)\n",
    "    output = tf.reshape(tf.concat(1, outputs), [-1, num_units])    \n",
    "    \n",
    "    print outputs\n",
    "    print output\n",
    "   \n",
    "    logits = tf.matmul(output, softmax_w) + softmax_b\n",
    "    probs = tf.nn.softmax(logits)\n",
    "    \n",
    "    loss = seq2seq.sequence_loss_by_example([logits],\n",
    "                                            [tf.reshape(targets, [-1])],\n",
    "                                            [tf.ones([batch_size * seq_length])],\n",
    "                                            vocab_size)\n",
    "    lr = tf.Variable(0.0, trainable=False)\n",
    "    total_loss = tf.reduce_sum(loss) / batch_size / seq_length\n",
    "    optimizer = tf.train.AdamOptimizer(lr).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(sess, words, vocab, probs, num=200, prime='', sampling_type=1, pick=0):\n",
    "    \n",
    "    def weighted_pick(weights):\n",
    "        t = np.cumsum(weights)\n",
    "        s = np.sum(weights)\n",
    "        return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "\n",
    "    def beam_search_pick(weights):\n",
    "        probs[0] = weights\n",
    "        samples, scores = BeamSearch(probs).beamsearch(None, vocab.get(prime), None, 2, len(weights), False)\n",
    "        sampleweights = samples[np.argmax(scores)]\n",
    "        t = np.cumsum(sampleweights)\n",
    "        s = np.sum(sampleweights)\n",
    "        return(int(np.searchsorted(t, np.random.rand(1)*s)))\n",
    "    \n",
    "    state = sess.run(cell.zero_state(1, tf.float32))\n",
    "    print state\n",
    "    \n",
    "    if not len(prime) or prime == '':\n",
    "        prime = random.choice(list(vocab.keys()))\n",
    "    print prime\n",
    "    \n",
    "    for word in prime.split()[:-1]:\n",
    "        print word\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab.get(word,0)\n",
    "        feed = {input_data: x}\n",
    "        [state] = sess.run([last_state], feed)\n",
    "\n",
    "    ret = prime\n",
    "    word = prime.split()[-1]\n",
    "\n",
    "    for n in range(num):\n",
    "        x = np.zeros((1, 1))\n",
    "        x[0, 0] = vocab.get(word,0)\n",
    "        feed = {input_data: x}\n",
    "        [probs, state] = sess.run([probs, last_state], feed)\n",
    "        p = probs[0]\n",
    "\n",
    "        if pick == 1:\n",
    "            if sampling_type == 0:\n",
    "                sample = np.argmax(p)\n",
    "            elif sampling_type == 2:\n",
    "                if word == '\\n':\n",
    "                    sample = weighted_pick(p)\n",
    "                else:\n",
    "                    sample = np.argmax(p)\n",
    "            else: # sampling_type == 1 default:\n",
    "                sample = weighted_pick(p)\n",
    "        elif pick == 2:\n",
    "            sample = beam_search_pick(p)\n",
    "\n",
    "        pred = words[sample]\n",
    "        ret += ' ' + pred\n",
    "        word = pred\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.111006975174\n",
      "0.0787000656128\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.]]\n",
      "윌리엄\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 1) for Tensor u'Placeholder_7:0', which has shape '(3, 6)'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-245-fec6ec283d8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0melasped_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msample_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-244-ae25635efda8>\u001b[0m in \u001b[0;36msample\u001b[0;34m(sess, words, vocab, probs, num, prime, sampling_type, pick)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mfeed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yhhan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/yhhan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    941\u001b[0m                 \u001b[0;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    942\u001b[0m                 \u001b[0;34m'which has shape %r'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 943\u001b[0;31m                 % (np_val.shape, subfeed_t.name, str(subfeed_t.get_shape())))\n\u001b[0m\u001b[1;32m    944\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor %s may not be fed.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot feed value of shape (1, 1) for Tensor u'Placeholder_7:0', which has shape '(3, 6)'"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "\n",
    "    for e in range(0, num_epochs):\n",
    "        elasped_time = 0\n",
    "        start = time.time()\n",
    "        \n",
    "        for i in range(0, num_batches):\n",
    "            x, y = next_batch(i)\n",
    "            sess.run(tf.assign(lr, learning_rate * (decay_rate ** e)))\n",
    "            feed = {input_data: x, targets: y}\n",
    "            sess.run(optimizer, feed)\n",
    "            elasped_time = time.time() - start\n",
    "            print elasped_time\n",
    "\n",
    "    sample_text = sample(sess, words, vocab, probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
